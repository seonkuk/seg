{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import csv\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label=[cv2.imread('data/train_labels/img13labels-'+str(i+1).zfill(6)+'.png') for i in range(5285)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image=[cv2.imread('data/train_images/img-'+str(i+1).zfill(6)+'.jpg') for i in range(5285)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image=[cv2.imread('data/test_images/img-'+str(i+1).zfill(6)+'.jpg') for i in range(5050)]\n",
    "test_label=[cv2.imread('data/test_labels/img13labels-'+str(i+1).zfill(6)+'.png') for i in range(5050)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(530, 730, 3)\n(530, 730, 3)\n"
     ]
    }
   ],
   "source": [
    "print(train_image[0].shape)\n",
    "print(train_label[0].shape)\n",
    "cv2.imshow(\"test\",train_label[0])\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate=0.001\n",
    "training_epochs=100\n",
    "set=1000\n",
    "batch_size = 1000\n",
    "tf.reset_default_graph()\n",
    "x=tf.placeholder(tf.float32,[None,530,730,3])\n",
    "y=tf.placeholder(tf.float32, [None,530,730,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Placeholder:0\", shape=(?, 530, 730, 3), dtype=float32)\nTensor(\"Placeholder:0\", shape=(?, 530, 730, 3), dtype=float32)\n5285\n"
     ]
    }
   ],
   "source": [
    "print(x)\n",
    "print(x1)\n",
    "print(len(train_image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "w1_1=tf.get_variable(\"w1_1\", shape=[3,3,3,32], initializer=tf.contrib.layers.xavier_initializer_conv2d())\n",
    "w1_2=tf.get_variable(\"w1_2\", shape=[3,3,32,32], initializer=tf.contrib.layers.xavier_initializer_conv2d())\n",
    "w2_1=tf.get_variable(\"w2_1\", shape=[3,3,32,64], initializer=tf.contrib.layers.xavier_initializer_conv2d())\n",
    "w2_2=tf.get_variable(\"w2_2\", shape=[3,3,64,64], initializer=tf.contrib.layers.xavier_initializer_conv2d())\n",
    "w3_1=tf.get_variable(\"w3_1\", shape=[3,3,64,128], initializer=tf.contrib.layers.xavier_initializer_conv2d())\n",
    "w3_2=tf.get_variable(\"w3_2\", shape=[3,3,128,128], initializer=tf.contrib.layers.xavier_initializer_conv2d())\n",
    "w4_1=tf.get_variable(\"w4_1\", shape=[3,3,128,256], initializer=tf.contrib.layers.xavier_initializer_conv2d())\n",
    "w4_2=tf.get_variable(\"w4_2\", shape=[3,3,256,256], initializer=tf.contrib.layers.xavier_initializer_conv2d())\n",
    "w5_1=tf.get_variable(\"w5_1\", shape=[3,3,256,512], initializer=tf.contrib.layers.xavier_initializer_conv2d())\n",
    "\n",
    "b1_1=tf.Variable(tf.random_normal([32]))\n",
    "b1_2=tf.Variable(tf.random_normal([32])) \n",
    "b2_1=tf.Variable(tf.random_normal([64])) \n",
    "b2_2=tf.Variable(tf.random_normal([64])) \n",
    "b3_1=tf.Variable(tf.random_normal([128])) \n",
    "b3_2=tf.Variable(tf.random_normal([128]))\n",
    "b4_1=tf.Variable(tf.random_normal([256]))\n",
    "b4_2=tf.Variable(tf.random_normal([256]))\n",
    "b5_1=tf.Variable(tf.random_normal([512]))\n",
    "\n",
    "l1_1=tf.nn.relu(tf.nn.conv2d(x,w1_1, strides=[1,1,1,1], padding= 'SAME')+b1_1)#(?,530,730,32)\n",
    "l1_2=tf.nn.relu(tf.nn.conv2d(l1_1,w1_2, strides=[1,1,1,1], padding= 'SAME')+b1_2)#(?,530,730,32)\n",
    "l1=tf.nn.max_pool(tf.nn.relu(l1_2), ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')#(?,265,365,32)\n",
    "\n",
    "\n",
    "l2_1=tf.nn.relu(tf.nn.conv2d(l1, w2_1, strides=[1,1,1,1], padding='SAME')+b2_1)#(?,265,365,64)\n",
    "l2_2=tf.nn.relu(tf.nn.conv2d(l2_1,w2_2, strides=[1,1,1,1], padding= 'SAME')+b2_2)#(?,265,365,64)\n",
    "l2=tf.nn.max_pool(tf.nn.relu(l2_2), ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')#(?,133,183,64)\n",
    "\n",
    "l3_1=tf.nn.relu(tf.nn.conv2d(l2, w3_1, strides=[1,1,1,1], padding='SAME')+b3_1)#(?,133,183,128)\n",
    "l3_2=tf.nn.relu(tf.nn.conv2d(l3_1,w3_2, strides=[1,1,1,1], padding= 'SAME')+b3_2)#(?,133,183,128)\n",
    "l3=tf.nn.max_pool(tf.nn.relu(l3_1), ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')#(?,67,92,128)\n",
    "\n",
    "l4_1=tf.nn.relu(tf.nn.conv2d(l3, w4_1, strides=[1,1,1,1], padding='SAME')+b4_1)#(?,67,92,256)\n",
    "l4_2=tf.nn.relu(tf.nn.conv2d(l4_1,w4_2, strides=[1,1,1,1], padding= 'SAME')+b4_2)#(?,67,92,256)\n",
    "l4=tf.nn.max_pool(tf.nn.relu(l4_2), ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')#(?,34,46,256)    \n",
    "\n",
    "l5_1=tf.nn.relu(tf.nn.conv2d(l4, w5_1, strides=[1,1,1,1], padding='SAME')+b5_1)#(?,67,92,256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"MaxPool:0\", shape=(?, 265, 365, 32), dtype=float32)\nTensor(\"MaxPool_1:0\", shape=(?, 133, 183, 64), dtype=float32)\nTensor(\"MaxPool_2:0\", shape=(?, 67, 92, 128), dtype=float32)\nTensor(\"MaxPool_3:0\", shape=(?, 34, 46, 256), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(l1)\n",
    "print(l2)\n",
    "print(l3)\n",
    "print(l4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_y=-y+1\n",
    "cost=tf.reduce_sum(new_y*tf.tan(np.pi/2*output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#entropy=-y*tf.log(out)\n",
    "#cross_entropy=tf.reduce_mean(entropy)\n",
    "#cross_entropy=tf.reduce_sum(tf.nn.softmax_cross_entropy_with_logits(logits=output,labels=y))\n",
    "optimizer=tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(output,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning start\n",
      "epoch :  0 cost :  1095.14\n",
      "epoch :  1 cost :  1004.05\n",
      "epoch :  2 cost :  1004.21\n"
     ]
    }
   ],
   "source": [
    "print(\"Learning start\")\n",
    "sess=tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "\n",
    "for epoch in range(training_epochs):\n",
    "    a=0\n",
    "    total_batch = int(len(train_image)/batch_size)+1\n",
    "\n",
    "    for i in range(total_batch):\n",
    "        if a+batch_size>len(train_image):\n",
    "            batch_xs=train_image[a:]\n",
    "            batch_ys=train_label[a:]\n",
    "        else:\n",
    "            batch_xs=train_image[a:a+batch_size]\n",
    "            batch_ys=train_label[a:a+batch_size]\n",
    "        feed_dict={x1:batch_xs, y:batch_ys}\n",
    "        c,_=sess.run([cost,optimizer], feed_dict=feed_dict)\n",
    "        a=a+batch_size\n",
    "\n",
    "    print(\"epoch : \",epoch,\"cost : \", c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-754532db901a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcor_pre\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mequal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marg_max\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marg_max\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0macc_\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcor_pre\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtest_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtest_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_conv\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m0.8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_hidden\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtest_acc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macc_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"accuracy : \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tf' is not defined"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "cor_pre=tf.equal(tf.arg_max(output,1),tf.arg_max(y,1))\n",
    "acc_=tf.reduce_mean(tf.cast(cor_pre,tf.float32))\n",
    "feed_dict={x1:test_image, y:test_label, keep_conv:0.8, keep_hidden:0.5}\n",
    "test_acc=sess.run(acc_,feed_dict=feed_dict)\n",
    "print(\"accuracy : \", test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}