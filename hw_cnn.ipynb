{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_label(x):\n",
    "    arr=np.zeros((7))\n",
    "    if x=='0':\n",
    "        arr[0]=1\n",
    "    elif x=='1':\n",
    "        arr[1]=1\n",
    "    elif x=='2':\n",
    "        arr[2]=1\n",
    "    elif x=='3':\n",
    "        arr[3]=1\n",
    "    elif x=='4':\n",
    "        arr[4]=1\n",
    "    elif x=='5':\n",
    "        arr[5]=1\n",
    "    else:\n",
    "        arr[6]=1\n",
    "    \n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_data(data):\n",
    "    label=[]\n",
    "    image=[]\n",
    "    type=[]\n",
    "    # with open(data,'r') as read:\n",
    "    #     for line in read:\n",
    "    #         sam=line.strip().split(' ')\n",
    "    #         label.append(sam[0])\n",
    "    #         image.append(np.array(sam[1:-1]))\n",
    "    #         type.append(sam[-1])\n",
    "    \n",
    "    with open(data,'r') as read:\n",
    "        line=read.readlines()\n",
    "    sample=csv.reader(line)\n",
    "    for sam in sample:\n",
    "        im=[int(i) for i in sam[1].split(' ')]\n",
    "        label.append(make_label(sam[0]))\n",
    "        image.append(np.array(im))\n",
    "        type.append(sam[-1])\n",
    "    return label, image, type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "label, image, type=read_data('fer.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_image=[]\n",
    "train_label=[]\n",
    "test_image=[]\n",
    "test_label=[]\n",
    "\n",
    "for i in range(len(type)):\n",
    "    if type[i]=='Training':\n",
    "        train_image.append(image[i])\n",
    "        train_label.append(label[i])\n",
    "    elif type[i]=='PublicTest':\n",
    "        test_image.append(image[i])\n",
    "        test_label.append(label[i])\n",
    "train_image=np.reshape(train_image,[len(train_image),2304])\n",
    "train_label=np.reshape(train_label,[len(train_label),7])\n",
    "test_image=np.reshape(test_image,[len(test_image),2304])\n",
    "test_label=np.reshape(test_label,[len(test_label),7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate=0.001\n",
    "training_epochs=100\n",
    "set=1000\n",
    "batch_size = 1000\n",
    "\n",
    "x1=tf.placeholder(tf.float32,[None,2304])\n",
    "y=tf.placeholder(tf.float32, [None,7])\n",
    "\n",
    "x=tf.reshape(x1,[-1,48,48,1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Reshape:0\", shape=(?, 48, 48, 1), dtype=float32)\n",
      "Tensor(\"Placeholder:0\", shape=(?, 2304), dtype=float32)\n",
      "28709\n"
     ]
    }
   ],
   "source": [
    "print(x)\n",
    "print(x1)\n",
    "print(len(train_image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.name_scope('weight'):\n",
    "    w1_1=tf.get_variable(\"w1_1\", shape=[3,3,1,32], initializer=tf.contrib.layers.xavier_initializer_conv2d())\n",
    "    w1_2=tf.get_variable(\"w1_2\", shape=[3,3,32,32], initializer=tf.contrib.layers.xavier_initializer_conv2d())\n",
    "    w2_1=tf.get_variable(\"w2_1\", shape=[3,3,32,64], initializer=tf.contrib.layers.xavier_initializer_conv2d())\n",
    "    w2_2=tf.get_variable(\"w2_2\", shape=[3,3,64,64], initializer=tf.contrib.layers.xavier_initializer_conv2d())\n",
    "    w3_1=tf.get_variable(\"w3_1\", shape=[3,3,64,128], initializer=tf.contrib.layers.xavier_initializer_conv2d())\n",
    "    w3_2=tf.get_variable(\"w3_2\", shape=[3,3,128,128], initializer=tf.contrib.layers.xavier_initializer_conv2d())\n",
    "    w4_1=tf.get_variable(\"w4_1\", shape=[3,3,128,256], initializer=tf.contrib.layers.xavier_initializer_conv2d())\n",
    "    w4_2=tf.get_variable(\"w4_2\", shape=[3,3,256,256], initializer=tf.contrib.layers.xavier_initializer_conv2d())\n",
    "    b1_1=tf.Variable(tf.random_normal([32]))\n",
    "    b1_2=tf.Variable(tf.random_normal([32])) \n",
    "    b2_1=tf.Variable(tf.random_normal([64])) \n",
    "    b2_2=tf.Variable(tf.random_normal([64])) \n",
    "    b3_1=tf.Variable(tf.random_normal([128])) \n",
    "    b3_2=tf.Variable(tf.random_normal([128]))\n",
    "    b4_1=tf.Variable(tf.random_normal([256]))\n",
    "    b4_2=tf.Variable(tf.random_normal([256]))\n",
    "\n",
    "\n",
    "    w5=tf.get_variable(\"w5\", shape=[3*3*256,1024], initializer=tf.contrib.layers.xavier_initializer())\n",
    "    b5=tf.Variable(tf.random_normal([1024]))   \n",
    "    w6=tf.get_variable(\"w6\", shape=[1024,256], initializer=tf.contrib.layers.xavier_initializer())\n",
    "    b6=tf.Variable(tf.random_normal([256]))    \n",
    "    w7=tf.get_variable(\"w7\", shape=[256,7], initializer=tf.contrib.layers.xavier_initializer())\n",
    "    b7=tf.Variable(tf.random_normal([7]))\n",
    "\n",
    "with tf.name_scope('layer'):\n",
    "    l1_1=tf.nn.relu(tf.nn.conv2d(x,w1_1, strides=[1,1,1,1], padding= 'SAME')+b1_1)\n",
    "    l1_2=tf.nn.relu(tf.nn.conv2d(l1_1,w1_2, strides=[1,1,1,1], padding= 'SAME')+b1_2)\n",
    "    l1=tf.nn.max_pool(tf.nn.relu(l1_2), ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')#(?,24,24,64)\n",
    "\n",
    "    \n",
    "    l2_1=tf.nn.relu(tf.nn.conv2d(l1, w2_1, strides=[1,1,1,1], padding='SAME')+b2_1)\n",
    "    l2_2=tf.nn.relu(tf.nn.conv2d(l2_1,w2_2, strides=[1,1,1,1], padding= 'SAME')+b2_2)\n",
    "    l2=tf.nn.max_pool(tf.nn.relu(l2_2), ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')#(?,12,12,64)\n",
    "\n",
    "    l3_1=tf.nn.relu(tf.nn.conv2d(l2, w3_1, strides=[1,1,1,1], padding='SAME')+b3_1)\n",
    "    l3_2=tf.nn.relu(tf.nn.conv2d(l3_1,w3_2, strides=[1,1,1,1], padding= 'SAME')+b3_2)\n",
    "    l3=tf.nn.max_pool(tf.nn.relu(l3_1), ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')#(?6,6,128)\n",
    "    \n",
    "    l4_1=tf.nn.relu(tf.nn.conv2d(l3, w4_1, strides=[1,1,1,1], padding='SAME')+b4_1)\n",
    "    l4_2=tf.nn.relu(tf.nn.conv2d(l4_1,w4_2, strides=[1,1,1,1], padding= 'SAME')+b4_2)\n",
    "    l4=tf.nn.max_pool(tf.nn.relu(l4_2), ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')#(?3,3,256)    \n",
    "    l4_flat=tf.reshape(l4,[-1,3*3*256])\n",
    "    \n",
    "    l5=tf.nn.relu(tf.matmul(l4_flat, w5)+b5)\n",
    "    \n",
    "    l6=tf.nn.relu(tf.matmul(l5, w6)+b6)\n",
    "    \n",
    "    output=tf.nn.softmax(tf.matmul(l6,w7)+b7)\n",
    "    #out=tf.nn.softmax(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_y=-y+1\n",
    "cost=tf.reduce_sum(new_y*tf.tan(np.pi/2*tf.nn.softmax(output)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#entropy=-y*tf.log(out)\n",
    "#cross_entropy=tf.reduce_mean(entropy)\n",
    "cross_entropy=tf.reduce_sum(tf.nn.softmax_cross_entropy_with_logits(logits=output,labels=y))\n",
    "optimizer=tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cross_entropy)\n",
    "correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(output,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning start\n",
      "1431.7\n",
      "1386.62\n",
      "1396.45\n",
      "1398.2\n",
      "1392.24\n",
      "1390.83\n",
      "1396.45\n",
      "1392.94\n",
      "1399.26\n",
      "1396.45\n",
      "1391.54\n",
      "1399.26\n",
      "1397.15\n",
      "1398.91\n",
      "1401.36\n",
      "1395.75\n",
      "1394.69\n",
      "1392.59\n",
      "1382.06\n",
      "1395.05\n",
      "1398.91\n",
      "1397.85\n",
      "1397.85\n",
      "1399.61\n",
      "1396.45\n",
      "1398.2\n",
      "1390.48\n",
      "1391.19\n",
      "985.407\n",
      "epoch :  0 cost :  1426.29\n",
      "1390.13\n",
      "1391.54\n",
      "1396.45\n",
      "1398.2\n",
      "1392.24\n",
      "1390.83\n",
      "1396.45\n",
      "1392.94\n",
      "1399.26\n",
      "1396.45\n",
      "1391.54\n",
      "1399.26\n",
      "1397.15\n",
      "1398.91\n",
      "1401.36\n",
      "1395.75\n",
      "1394.69\n",
      "1392.59\n",
      "1382.06\n",
      "1395.05\n",
      "1398.91\n",
      "1397.85\n",
      "1397.85\n",
      "1399.61\n",
      "1396.45\n",
      "1398.2\n",
      "1390.48\n",
      "1391.19\n",
      "985.407\n",
      "epoch :  1 cost :  1426.29\n",
      "1390.13\n",
      "1391.54\n",
      "1396.45\n",
      "1398.2\n",
      "1392.24\n",
      "1390.83\n",
      "1396.45\n",
      "1392.94\n",
      "1399.26\n",
      "1396.45\n",
      "1391.54\n",
      "1399.26\n",
      "1397.15\n",
      "1398.91\n",
      "1401.36\n",
      "1395.75\n",
      "1394.69\n",
      "1392.59\n",
      "1382.06\n",
      "1395.05\n",
      "1398.91\n",
      "1397.85\n",
      "1397.85\n",
      "1399.61\n",
      "1396.45\n",
      "1398.2\n",
      "1390.48\n",
      "1391.19\n",
      "985.407\n",
      "epoch :  2 cost :  1426.29\n",
      "1390.13\n",
      "1391.54\n",
      "1396.45\n",
      "1398.2\n",
      "1392.24\n",
      "1390.83\n",
      "1396.45\n",
      "1392.94\n",
      "1399.26\n",
      "1396.45\n",
      "1391.54\n",
      "1399.26\n",
      "1397.15\n",
      "1398.91\n",
      "1401.36\n",
      "1395.75\n",
      "1394.69\n",
      "1392.59\n",
      "1382.06\n",
      "1395.05\n",
      "1398.91\n",
      "1397.85\n",
      "1397.85\n",
      "1399.61\n",
      "1396.45\n",
      "1398.2\n",
      "1390.48\n",
      "1391.19\n",
      "985.407\n",
      "epoch :  3 cost :  1426.29\n",
      "1390.13\n",
      "1391.54\n",
      "1396.45\n",
      "1398.2\n",
      "1392.24\n",
      "1390.83\n",
      "1396.45\n",
      "1392.94\n",
      "1399.26\n",
      "1396.45\n",
      "1391.54\n",
      "1399.26\n",
      "1397.15\n",
      "1398.91\n",
      "1401.36\n",
      "1395.75\n",
      "1394.69\n",
      "1392.59\n",
      "1382.06\n",
      "1395.05\n",
      "1398.91\n",
      "1397.85\n",
      "1397.85\n",
      "1399.61\n",
      "1396.45\n",
      "1398.2\n",
      "1390.48\n",
      "1391.19\n",
      "985.407\n",
      "epoch :  4 cost :  1426.29\n",
      "1390.13\n",
      "1391.54\n",
      "1396.45\n",
      "1398.2\n",
      "1392.24\n",
      "1390.83\n",
      "1396.45\n",
      "1392.94\n",
      "1399.26\n",
      "1396.45\n",
      "1391.54\n",
      "1399.26\n",
      "1397.15\n",
      "1398.91\n",
      "1401.36\n",
      "1395.75\n",
      "1394.69\n",
      "1392.59\n",
      "1382.06\n",
      "1395.05\n",
      "1398.91\n",
      "1397.85\n",
      "1397.85\n",
      "1399.61\n",
      "1396.45\n",
      "1398.2\n",
      "1390.48\n",
      "1391.19\n",
      "985.407\n",
      "epoch :  5 cost :  1426.29\n",
      "1390.13\n",
      "1391.54\n",
      "1396.45\n",
      "1398.2\n",
      "1392.24\n",
      "1390.83\n",
      "1396.45\n",
      "1392.94\n",
      "1399.26\n",
      "1396.45\n",
      "1391.54\n",
      "1399.26\n",
      "1397.15\n",
      "1398.91\n",
      "1401.36\n",
      "1395.75\n",
      "1394.69\n",
      "1392.59\n",
      "1382.06\n",
      "1395.05\n",
      "1398.91\n",
      "1397.85\n",
      "1397.85\n",
      "1399.61\n",
      "1396.45\n",
      "1398.2\n",
      "1390.48\n",
      "1391.19\n",
      "985.407\n",
      "epoch :  6 cost :  1426.29\n",
      "1390.13\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-d7a74765620d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0mbatch_ys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_label\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbatch_xs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbatch_ys\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mco\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcost\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mco\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/gpu2/anaconda3/envs/dlsw/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 778\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    779\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/gpu2/anaconda3/envs/dlsw/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    980\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 982\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    983\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/gpu2/anaconda3/envs/dlsw/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1030\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1032\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1033\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/home/gpu2/anaconda3/envs/dlsw/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1037\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1040\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/gpu2/anaconda3/envs/dlsw/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1019\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1020\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(\"Learning start\")\n",
    "sess=tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "\n",
    "for epoch in range(training_epochs):\n",
    "    a=0\n",
    "    total_batch = int(len(train_image)/batch_size)+1\n",
    "\n",
    "    for i in range(total_batch):\n",
    "        if a+batch_size>train_image.shape[0]:\n",
    "            batch_xs=train_image[a:]\n",
    "            batch_ys=train_label[a:]\n",
    "        else:\n",
    "            batch_xs=train_image[a:a+batch_size]\n",
    "            batch_ys=train_label[a:a+batch_size]\n",
    "        feed_dict={x1:batch_xs, y:batch_ys}\n",
    "        co,c,_=sess.run([cost,cross_entropy,optimizer], feed_dict=feed_dict)\n",
    "        print(co)\n",
    "        \n",
    "        a=a+batch_size\n",
    "\n",
    "    print(\"epoch : \",epoch,\"cost : \", c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-754532db901a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcor_pre\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mequal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marg_max\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marg_max\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0macc_\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcor_pre\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtest_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtest_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_conv\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m0.8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_hidden\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtest_acc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macc_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"accuracy : \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "cor_pre=tf.equal(tf.arg_max(output,1),tf.arg_max(y,1))\n",
    "acc_=tf.reduce_mean(tf.cast(cor_pre,tf.float32))\n",
    "feed_dict={x1:test_image, y:test_label, keep_conv:0.8, keep_hidden:0.5}\n",
    "test_acc=sess.run(acc_,feed_dict=feed_dict)\n",
    "print(\"accuracy : \", test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
