{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import csv\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 0]\n",
      " [1 1 0]]\n"
     ]
    }
   ],
   "source": [
    "arr=np.array([[0,0,0],[0,0,0]])\n",
    "arr1=np.array([0,0,1])\n",
    "arr[:,arr1]=1\n",
    "print(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_oneshot(label):\n",
    "    new_label=[]\n",
    "    for i in range(len(label)):\n",
    "        arr=np.zeros([label[0].shape[0],label[0].shape[1],64])\n",
    "        for x in range(label[0].shape[0]):\n",
    "            for y in range(label[0].shape[1]):\n",
    "                arr[x,y,label[i][x,y,0]]=1\n",
    "        new_label.append(arr)\n",
    "    return new_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label=[cv2.imread('data/train_labels/img13labels-'+str(i+1).zfill(6)+'.png') for i in range(100)]#5285"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image=[cv2.imread('data/train_images/img-'+str(i+1).zfill(6)+'.jpg') for i in range(100)]#5285"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image=[cv2.imread('data/test_images/img-'+str(i+1).zfill(6)+'.jpg') for i in range(100)]#5050\n",
    "test_label=[cv2.imread('data/test_labels/img13labels-'+str(i+1).zfill(6)+'.png') for i in range(100)]#5050"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_resize(img):\n",
    "    for i in range(len(img)):\n",
    "        img[i]=cv2.resize(img[i], None, fx=0.5, fy=0.5, interpolation=cv2.INTER_AREA)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image=img_resize(train_image)\n",
    "train_label=img_resize(train_label)\n",
    "test_label=img_resize(test_label)\n",
    "test_image=img_resize(test_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(530, 730, 3)\n"
     ]
    }
   ],
   "source": [
    "print(train_label[0].shape)\n",
    "# cv2.imshow(\"test\",train_image[0])\n",
    "# cv2.waitKey()\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train_label=label_oneshot(train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=np.zeros([train_label[0].shape[0]*train_label[0].shape[1],64])\n",
    "b=train_label[0][:,:,0].flatten()\n",
    "for i in range(b.shape[0]):\n",
    "    a[i,b[i]]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=train_label[0]\n",
    "a=np.minimum(a*30,255)\n",
    "a1=a[:,:,0]\n",
    "a2=a[:,:,1]\n",
    "a3=a2-a1\n",
    "cv2.imshow(\"test1\",a1)\n",
    "cv2.imshow(\"test2\",a2)\n",
    "cv2.imshow(\"test3\",a3)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate=0.001\n",
    "training_epochs=100\n",
    "set=10\n",
    "batch_size = 10\n",
    "tf.reset_default_graph()\n",
    "x=tf.placeholder(tf.float32,[None,530,730,3])\n",
    "y=tf.placeholder(tf.float32, [None,530,730,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Placeholder:0\", shape=(?, 530, 730, 3), dtype=float32)\n",
      "5285\n"
     ]
    }
   ],
   "source": [
    "print(x)\n",
    "print(len(train_image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "w1_1=tf.get_variable(\"w1_1\", shape=[3,3,3,64], initializer=tf.contrib.layers.xavier_initializer_conv2d())\n",
    "w1_2=tf.get_variable(\"w1_2\", shape=[3,3,64,64], initializer=tf.contrib.layers.xavier_initializer_conv2d())\n",
    "w2_1=tf.get_variable(\"w2_1\", shape=[3,3,64,128], initializer=tf.contrib.layers.xavier_initializer_conv2d())\n",
    "w2_2=tf.get_variable(\"w2_2\", shape=[3,3,128,128], initializer=tf.contrib.layers.xavier_initializer_conv2d())\n",
    "w3_1=tf.get_variable(\"w3_1\", shape=[3,3,128,256], initializer=tf.contrib.layers.xavier_initializer_conv2d())\n",
    "w3_2=tf.get_variable(\"w3_2\", shape=[3,3,256,256], initializer=tf.contrib.layers.xavier_initializer_conv2d())\n",
    "w4_1=tf.get_variable(\"w4_1\", shape=[3,3,256,512], initializer=tf.contrib.layers.xavier_initializer_conv2d())\n",
    "w4_2=tf.get_variable(\"w4_2\", shape=[3,3,512,512], initializer=tf.contrib.layers.xavier_initializer_conv2d())\n",
    "w5_1=tf.get_variable(\"w5_1\", shape=[3,3,512,512], initializer=tf.contrib.layers.xavier_initializer_conv2d())\n",
    "\n",
    "w6_1=tf.get_variable(\"w6_1\", shape=[3,3,512,512], initializer=tf.contrib.layers.xavier_initializer_conv2d())\n",
    "w6_2=tf.get_variable(\"w6_2\", shape=[3,3,512,512], initializer=tf.contrib.layers.xavier_initializer_conv2d())\n",
    "w7_1=tf.get_variable(\"w7_1\", shape=[3,3,512,256], initializer=tf.contrib.layers.xavier_initializer_conv2d())\n",
    "w7_2=tf.get_variable(\"w7_2\", shape=[3,3,256,256], initializer=tf.contrib.layers.xavier_initializer_conv2d())\n",
    "w8_1=tf.get_variable(\"w8_1\", shape=[3,3,256,128], initializer=tf.contrib.layers.xavier_initializer_conv2d())\n",
    "w8_2=tf.get_variable(\"w8_2\", shape=[3,3,128,128], initializer=tf.contrib.layers.xavier_initializer_conv2d())\n",
    "w9_1=tf.get_variable(\"w9_1\", shape=[3,3,128,64], initializer=tf.contrib.layers.xavier_initializer_conv2d())\n",
    "w9_2=tf.get_variable(\"w9_2\", shape=[3,3,64,64], initializer=tf.contrib.layers.xavier_initializer_conv2d())\n",
    "\n",
    "\n",
    "b1_1=tf.Variable(tf.random_normal([64]))\n",
    "b1_2=tf.Variable(tf.random_normal([64])) \n",
    "b2_1=tf.Variable(tf.random_normal([128])) \n",
    "b2_2=tf.Variable(tf.random_normal([128])) \n",
    "b3_1=tf.Variable(tf.random_normal([256])) \n",
    "b3_2=tf.Variable(tf.random_normal([256]))\n",
    "b4_1=tf.Variable(tf.random_normal([512]))\n",
    "b4_2=tf.Variable(tf.random_normal([512]))\n",
    "b5_1=tf.Variable(tf.random_normal([512]))\n",
    "\n",
    "b6_1=tf.Variable(tf.random_normal([512]))\n",
    "b6_2=tf.Variable(tf.random_normal([512]))\n",
    "b7_1=tf.Variable(tf.random_normal([256]))\n",
    "b7_2=tf.Variable(tf.random_normal([256]))\n",
    "b8_1=tf.Variable(tf.random_normal([128]))\n",
    "b8_2=tf.Variable(tf.random_normal([128]))\n",
    "b9_1=tf.Variable(tf.random_normal([64]))\n",
    "b9_2=tf.Variable(tf.random_normal([64]))\n",
    "\n",
    "l1_1=tf.nn.relu(tf.nn.conv2d(x,w1_1, strides=[1,1,1,1], padding= 'SAME')+b1_1)#(?,530,730,32)\n",
    "l1_2=tf.nn.relu(tf.nn.conv2d(l1_1,w1_2, strides=[1,1,1,1], padding= 'SAME')+b1_2)#(?,530,730,32)\n",
    "l1=tf.nn.max_pool(tf.nn.relu(l1_2), ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')#(?,265,365,32)\n",
    "\n",
    "l2_1=tf.nn.relu(tf.nn.conv2d(l1, w2_1, strides=[1,1,1,1], padding='SAME')+b2_1)#(?,265,365,64)\n",
    "l2_2=tf.nn.relu(tf.nn.conv2d(l2_1,w2_2, strides=[1,1,1,1], padding= 'SAME')+b2_2)#(?,265,365,64)\n",
    "l2=tf.nn.max_pool(tf.nn.relu(l2_2), ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')#(?,133,183,64)\n",
    "\n",
    "l3_1=tf.nn.relu(tf.nn.conv2d(l2, w3_1, strides=[1,1,1,1], padding='SAME')+b3_1)#(?,133,183,128)\n",
    "l3_2=tf.nn.relu(tf.nn.conv2d(l3_1,w3_2, strides=[1,1,1,1], padding= 'SAME')+b3_2)#(?,133,183,128)\n",
    "l3=tf.nn.max_pool(tf.nn.relu(l3_1), ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')#(?,67,92,128)\n",
    "\n",
    "l4_1=tf.nn.relu(tf.nn.conv2d(l3, w4_1, strides=[1,1,1,1], padding='SAME')+b4_1)#(?,67,92,256)\n",
    "l4_2=tf.nn.relu(tf.nn.conv2d(l4_1,w4_2, strides=[1,1,1,1], padding= 'SAME')+b4_2)#(?,67,92,256)\n",
    "l4=tf.nn.max_pool(tf.nn.relu(l4_2), ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')#(?,34,46,256)    \n",
    "\n",
    "l5_1=tf.nn.relu(tf.nn.conv2d(l4, w5_1, strides=[1,1,1,1], padding='SAME')+b5_1)#(?,34,46,512)\n",
    "\n",
    "l6=tf.image.resize_images(l5_1,[67,92])\n",
    "l6_1=tf.nn.relu(tf.nn.conv2d(l6,w6_1, strides=[1,1,1,1], padding= 'SAME')+b6_1)#(?,67,92,512).\n",
    "l6_2=tf.nn.relu(tf.nn.conv2d(l6_1,w6_2, strides=[1,1,1,1], padding= 'SAME')+b6_2)#(?,67,92,512)\n",
    "\n",
    "l7=tf.image.resize_images(l6_2,[133,183])\n",
    "l7_1=tf.nn.relu(tf.nn.conv2d(l7,w7_1, strides=[1,1,1,1], padding= 'SAME')+b7_1)#(?,133,183,256)\n",
    "l7_2=tf.nn.relu(tf.nn.conv2d(l7_1,w7_2, strides=[1,1,1,1], padding= 'SAME')+b7_2)#(?,133,183,256)\n",
    "\n",
    "l8=tf.image.resize_images(l7_2,[265,365])\n",
    "l8_1=tf.nn.relu(tf.nn.conv2d(l8,w8_1, strides=[1,1,1,1], padding= 'SAME')+b8_1)#(?,265,365,128)\n",
    "l8_2=tf.nn.relu(tf.nn.conv2d(l8_1,w8_2, strides=[1,1,1,1], padding= 'SAME')+b8_2)#(?,265,365,128)\n",
    "\n",
    "l9=tf.image.resize_images(l8_2,[530,730])\n",
    "l9_1=tf.nn.relu(tf.nn.conv2d(l9,w9_1, strides=[1,1,1,1], padding= 'SAME')+b9_1)#(?,530,730,64)\n",
    "l9_2=tf.nn.relu(tf.nn.conv2d(l9_1,w9_2, strides=[1,1,1,1], padding= 'SAME')+b9_2)#(?,530,730,64)\n",
    "\n",
    "# l10=tf.nn.relu(tf.nn.conv2d(l9_2,w10_1, strides=[1,1,1,1], padding= 'SAME'))#(?,530,730,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"MaxPool:0\", shape=(?, 265, 365, 64), dtype=float32)\n",
      "Tensor(\"MaxPool_1:0\", shape=(?, 133, 183, 128), dtype=float32)\n",
      "Tensor(\"MaxPool_2:0\", shape=(?, 67, 92, 256), dtype=float32)\n",
      "Tensor(\"MaxPool_3:0\", shape=(?, 34, 46, 512), dtype=float32)\n",
      "Tensor(\"Relu_12:0\", shape=(?, 34, 46, 512), dtype=float32)\n",
      "Tensor(\"Relu_13:0\", shape=(?, 67, 92, 512), dtype=float32)\n",
      "Tensor(\"Relu_15:0\", shape=(?, 133, 183, 256), dtype=float32)\n",
      "Tensor(\"Relu_17:0\", shape=(?, 265, 365, 128), dtype=float32)\n",
      "Tensor(\"Relu_19:0\", shape=(?, 530, 730, 64), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(l1)\n",
    "print(l2)\n",
    "print(l3)\n",
    "print(l4)\n",
    "print(l5_1)\n",
    "print(l6_1)\n",
    "print(l7_1)\n",
    "print(l8_1)\n",
    "print(l9_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost=tf.reduce_mean(tf.square(l10-y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#entropy=-y*tf.log(out)\n",
    "#cross_entropy=tf.reduce_mean(entropy)\n",
    "#cross_entropy=tf.reduce_sum(tf.nn.softmax_cross_entropy_with_logits(logits=output,labels=y))\n",
    "optimizer=tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "# correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(l10,1))\n",
    "# accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning start\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-8c548697bd40>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0mbatch_ys\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_label\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mbatch_xs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mbatch_ys\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0m_\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcost\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0ma\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mc:\\users\\sh\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 778\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    779\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mc:\\users\\sh\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    980\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 982\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    983\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mc:\\users\\sh\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1030\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1032\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1033\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32mc:\\users\\sh\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1037\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1040\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mc:\\users\\sh\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1019\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1020\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1022\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(\"Learning start\")\n",
    "sess=tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "\n",
    "for epoch in range(training_epochs):\n",
    "    a=0\n",
    "    total_batch = int(len(train_image)/batch_size)+1\n",
    "\n",
    "    for i in range(total_batch):\n",
    "        if a+batch_size>len(train_image):\n",
    "            batch_xs=train_image[a:]\n",
    "            batch_ys=train_label[a:]\n",
    "        else:\n",
    "            batch_xs=train_image[a:a+batch_size]\n",
    "            batch_ys=train_label[a:a+batch_size]\n",
    "        feed_dict={x:batch_xs, y:batch_ys}\n",
    "        c,_=sess.run([cost,optimizer], feed_dict=feed_dict)\n",
    "        a=a+batch_size\n",
    "\n",
    "    print(\"epoch : \",epoch,\"cost : \", c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-754532db901a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcor_pre\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mequal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marg_max\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marg_max\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0macc_\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcor_pre\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtest_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtest_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_conv\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m0.8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_hidden\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtest_acc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macc_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"accuracy : \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "cor_pre=tf.equal(tf.arg_max(output,1),tf.arg_max(y,1))\n",
    "acc_=tf.reduce_mean(tf.cast(cor_pre,tf.float32))\n",
    "feed_dict={x1:test_image, y:test_label, keep_conv:0.8, keep_hidden:0.5}\n",
    "test_acc=sess.run(acc_,feed_dict=feed_dict)\n",
    "print(\"accuracy : \", test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
